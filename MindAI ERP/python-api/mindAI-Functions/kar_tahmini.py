import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from sklearn.model_selection import train_test_split
from sklearn.linear_model import BayesianRidge
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import MinMaxScaler
from scipy.stats import zscore

# ğŸ“ Ã‡Ä±ktÄ± KlasÃ¶rÃ¼nÃ¼ OluÅŸtur
ANALIZ_KLASORU = r"C:\Users\Hakan\Desktop\mindAI-Functions\analizler\kar-tahmini"
os.makedirs(ANALIZ_KLASORU, exist_ok=True)

# ğŸ“‚ CSV DosyasÄ±nÄ± ParÃ§a ParÃ§a Oku
csv_dosya = r"C:\Users\Hakan\Desktop\mindAI-Functions\transactions.csv"

chunk_size = 10000  # 10.000 satÄ±rlÄ±k bloklar halinde oku
df_list = []
for chunk in pd.read_csv(csv_dosya, chunksize=chunk_size):
    chunk.fillna(chunk.median(numeric_only=True), inplace=True)  # Eksik verileri doldur
    df_list.append(chunk)

df = pd.concat(df_list, ignore_index=True)

# ğŸ•µï¸ Veri Ã–nizleme
print("ğŸ” Veri Ã–nizleme:")
print(df.head())

# ğŸ“Š Eksik Veri Analizi
print("ğŸ” Eksik Veri SayÄ±larÄ±:")
print(df.isnull().sum())

# ğŸ“‰ AykÄ±rÄ± DeÄŸerleri Temizleme (Z-Score Kullanarak)
z_scores = df.select_dtypes(include=["number"]).apply(zscore)

df = df[(np.abs(z_scores) < 3).all(axis=1)]  # Z skoru 3â€™ten bÃ¼yÃ¼k olanlarÄ± kaldÄ±r

# ğŸ“Š Kategorik DeÄŸiÅŸkenleri Kontrol Et
categorical_cols = df.select_dtypes(include=["object"]).columns.tolist()

# ğŸ·ï¸ YÃ¼ksek kategorik deÄŸiÅŸkenleri azalt
MAX_CATEGORIES = 50
for col in categorical_cols:
    if df[col].nunique() > MAX_CATEGORIES:
        top_categories = df[col].value_counts().nlargest(MAX_CATEGORIES).index
        df[col] = df[col].apply(lambda x: x if x in top_categories else "Other")

# ğŸ”„ Bellek Dostu One-Hot Encoding (Sadece Ä°lk 50 Kategoriyi Koru)
df = pd.get_dummies(df, columns=categorical_cols, drop_first=True, dtype=np.float32)

# ğŸ—ï¸ Bellek Optimizasyonu: float64 â†’ float32, int64 â†’ int32
for col in df.select_dtypes(include=["float64"]).columns:
    df[col] = df[col].astype(np.float32)

for col in df.select_dtypes(include=["int64"]).columns:
    df[col] = df[col].astype(np.int32)

# ğŸ¯ GiriÅŸ ve Ã‡Ä±kÄ±ÅŸ DeÄŸiÅŸkenlerini SeÃ§
X = df.drop(columns=["profit"])  # Hedef deÄŸiÅŸken hariÃ§ tÃ¼m deÄŸiÅŸkenler
y = df["profit"]

# ğŸ“ Ã–lÃ§eklendirme (MinMaxScaler)
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# ğŸ“Š Veri Setini EÄŸitim ve Test Olarak AyÄ±r
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# ğŸ“ˆ Bayesian Ridge Regression Modelini EÄŸitme
model = BayesianRidge()
model.fit(X_train, y_train)

# ğŸ“Š Tahmin Yapma
y_pred = model.predict(X_test)

# ğŸ¯ Model Performans Metrikleri
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

# ğŸ“ˆ GerÃ§ek ve Tahmin Edilen DeÄŸerleri KarÅŸÄ±laÅŸtÄ±rma GrafiÄŸi
GRAFIK_DOSYA = os.path.join(ANALIZ_KLASORU, "kar_tahmin_grafik.png")

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5, color="blue", label="GerÃ§ek vs Tahmin")
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle="--", color="red", label="MÃ¼kemmel DoÄŸrusal")
plt.xlabel("GerÃ§ek Kar ($)")
plt.ylabel("Tahmin Edilen Kar ($)")
plt.title("Kar Tahmini: Bayesian Regression")
plt.legend()
plt.grid(True)
plt.savefig(GRAFIK_DOSYA)
plt.close()

# ğŸ“œ TXT DosyasÄ±na Model BaÅŸarÄ±sÄ± ve KatsayÄ±larÄ± Yaz
TXT_DOSYA = os.path.join(ANALIZ_KLASORU, "kar_tahmin_analiz.txt")

with open(TXT_DOSYA, "w") as f:
    f.write("Kar Tahmini - Bayesian Ridge Regression Modeli\n")
    f.write("--------------------------------------------\n")
    f.write(f"R2 Skoru: {r2:.4f}\n")
    f.write(f"MAE (Ortalama Mutlak Hata): {mae:.2f}\n")
    f.write(f"RMSE (Karekok Ortalama Kare Hata): {rmse:.2f}\n")
    f.write("\nModel KatsayÄ±larÄ±:\n")
    for col, coef in zip(X.columns, model.coef_):
        f.write(f"{col}: {coef:.4f}\n")

# ğŸ† Modelin BaÅŸarÄ± Raporunu YazdÄ±r
print(f"âœ… GeliÅŸtirilmiÅŸ Regresyon Analizi TamamlandÄ±! SonuÃ§lar Kaydedildi: {TXT_DOSYA}")
